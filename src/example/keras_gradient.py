import pandas as pd
from keras.layers import Dense, Activation
from keras.models import Sequential
import keras.backend as K
import tensorflow as tf
import numpy as np
from src.saved_models.mnist_ann_keras import MNIST

def plot_image():
    import matplotlib.pyplot as plt
    img = x_new.reshape(28, 28)
    plt.imshow(img, cmap='gray')
    plt.title(f'An adversarial sample generated by ')
    plt.show()

if __name__ == '__main__':
    mnist = MNIST()
    mnist.set_num_classes(10)
    model = mnist.load_model(
        weight_path='/home/pass-la-1/PycharmProjects/mydeepconcolic/src/saved_models/mnist_ann_keras_f1_original.h5',
        structure_path='/home/pass-la-1/PycharmProjects/mydeepconcolic/src/saved_models/mnist_ann_keras_f1_original.json',
        trainset_path='/home/pass-la-1/PycharmProjects/mydeepconcolic/dataset/digit-recognizer/train.csv')
    mnist.read_data(
        trainset_path='/home/pass-la-1/PycharmProjects/mydeepconcolic/dataset/digit-recognizer/train.csv',
        testset_path='/home/pass-la-1/PycharmProjects/mydeepconcolic/dataset/digit-recognizer/test.csv')

    # get model
    model = mnist.get_model()
    assert (isinstance(model, Sequential))
    print(f"model output = {model.output}")
    print(f"model input = {model.input}")

    # get a seed
    x_train, y_train = mnist.get_an_observation_from_train_set(index=10)
    x_train = x_train.reshape(1, -1)
    print(f'x_train shape = {x_train.shape}')
    # print(f'x_train = {x_train}')
    # print(f"y_train = {y_train}")

    # construct loss gradients
    loss = K.sum(K.categorical_crossentropy(target=[1, 0, 0, 0, 0, 0, 0, 0, 0, 0], output=model.output))
    loss_gradients = K.gradients(loss=loss, variables=model.input)  # Gradient of output wrt the input of the model (Tensor)
    print(f"loss_gradients = {loss_gradients}")

    # compute gradient
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        grad = sess.run(loss_gradients, feed_dict={model.input: x_train})[0]
        sign = np.sign(grad)
        print(f"evaluated_gradients_1 = {grad}")
        print(f"sign of evaluated_gradients_1 = {sign}")

        e = 0.1
        x_new = x_train + sign * e
        print(x_new)

